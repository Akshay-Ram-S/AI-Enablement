{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EiykKcpI1Riz"
      },
      "outputs": [],
      "source": [
        "!pip install -qU chromadb openai pypdf2 python-docx python-multipart sentence-transformers python-docs PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import docx\n",
        "import PyPDF2\n",
        "import os\n",
        "\n",
        "def read_text_file(file_path: str):\n",
        "    \"\"\"Read content from a text file\"\"\"\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        return file.read()\n",
        "\n",
        "def read_pdf_file(file_path: str):\n",
        "    \"\"\"Read content from a PDF file\"\"\"\n",
        "    text = \"\"\n",
        "    with open(file_path, 'rb') as file:\n",
        "        pdf_reader = PyPDF2.PdfReader(file)\n",
        "        for page in pdf_reader.pages:\n",
        "            text += page.extract_text() + \"\\n\"\n",
        "    return text\n",
        "\n",
        "def read_docx_file(file_path: str):\n",
        "    \"\"\"Read content from a Word document\"\"\"\n",
        "    doc = docx.Document(file_path)\n",
        "    return \"\\n\".join([paragraph.text for paragraph in doc.paragraphs])\n"
      ],
      "metadata": {
        "id": "zGFRJX9x1lzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_document(file_path: str):\n",
        "    \"\"\"Read document content based on file extension\"\"\"\n",
        "    _, file_extension = os.path.splitext(file_path)\n",
        "    file_extension = file_extension.lower()\n",
        "\n",
        "    if file_extension == '.txt':\n",
        "        return read_text_file(file_path)\n",
        "    elif file_extension == '.pdf':\n",
        "        return read_pdf_file(file_path)\n",
        "    elif file_extension == '.docx':\n",
        "        return read_docx_file(file_path)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported file format: {file_extension}\")\n"
      ],
      "metadata": {
        "id": "15aVmNqq1xq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_text(text: str, chunk_size: int = 500):\n",
        "    \"\"\"Split text into chunks while preserving sentence boundaries\"\"\"\n",
        "    sentences = text.replace('\\n', ' ').split('. ')\n",
        "    chunks = []\n",
        "    current_chunk = []\n",
        "    current_size = 0\n",
        "\n",
        "    for sentence in sentences:\n",
        "        sentence = sentence.strip()\n",
        "        if not sentence:\n",
        "            continue\n",
        "\n",
        "        # Ensure proper sentence ending\n",
        "        if not sentence.endswith('.'):\n",
        "            sentence += '.'\n",
        "\n",
        "        sentence_size = len(sentence)\n",
        "\n",
        "        # Check if adding this sentence would exceed chunk size\n",
        "        if current_size + sentence_size > chunk_size and current_chunk:\n",
        "            chunks.append(' '.join(current_chunk))\n",
        "            current_chunk = [sentence]\n",
        "            current_size = sentence_size\n",
        "        else:\n",
        "            current_chunk.append(sentence)\n",
        "            current_size += sentence_size\n",
        "\n",
        "    # Add the last chunk if it exists\n",
        "    if current_chunk:\n",
        "        chunks.append(' '.join(current_chunk))\n",
        "\n",
        "    return chunks\n"
      ],
      "metadata": {
        "id": "mYKyKwYV3PPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import chromadb\n",
        "from chromadb.utils import embedding_functions\n",
        "\n",
        "# Initialize ChromaDB client with persistence\n",
        "client = chromadb.PersistentClient(path=\"chroma_db\")\n",
        "\n",
        "# Configure sentence transformer embeddings\n",
        "sentence_transformer_ef = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
        "    model_name=\"all-MiniLM-L6-v2\"\n",
        ")\n",
        "\n",
        "# Create or get existing collection\n",
        "collection = client.get_or_create_collection(\n",
        "    name=\"documents_collection\",\n",
        "    embedding_function=sentence_transformer_ef\n",
        ")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "5YN2lFMG3dnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_document(file_path: str):\n",
        "    \"\"\"Process a single document and prepare it for ChromaDB\"\"\"\n",
        "    try:\n",
        "        # Read the document\n",
        "        content = read_document(file_path)\n",
        "\n",
        "        # Split into chunks\n",
        "        chunks = split_text(content)\n",
        "\n",
        "        # Prepare metadata\n",
        "        file_name = os.path.basename(file_path)\n",
        "        metadatas = [{\"source\": file_name, \"chunk\": i} for i in range(len(chunks))]\n",
        "        ids = [f\"{file_name}_chunk_{i}\" for i in range(len(chunks))]\n",
        "\n",
        "        return ids, chunks, metadatas\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {file_path}: {str(e)}\")\n",
        "        return [], [], []\n",
        "\n",
        "def add_to_collection(collection, ids, texts, metadatas):\n",
        "    \"\"\"Add documents to collection in batches\"\"\"\n",
        "    if not texts:\n",
        "        return\n",
        "\n",
        "    batch_size = 100\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        end_idx = min(i + batch_size, len(texts))\n",
        "        collection.add(\n",
        "            documents=texts[i:end_idx],\n",
        "            metadatas=metadatas[i:end_idx],\n",
        "            ids=ids[i:end_idx]\n",
        "        )\n",
        "\n",
        "def process_and_add_documents(collection, folder_path: str):\n",
        "    \"\"\"Process all documents in a folder and add to collection\"\"\"\n",
        "    files = [os.path.join(folder_path, file)\n",
        "             for file in os.listdir(folder_path)\n",
        "             if os.path.isfile(os.path.join(folder_path, file))]\n",
        "\n",
        "    for file_path in files:\n",
        "        print(f\"Processing {os.path.basename(file_path)}...\")\n",
        "        ids, texts, metadatas = process_document(file_path)\n",
        "        add_to_collection(collection, ids, texts, metadatas)\n",
        "        print(f\"Added {len(texts)} chunks to collection\")\n"
      ],
      "metadata": {
        "id": "fM3sbtXV5YwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize ChromaDB collection\n",
        "collection = client.get_or_create_collection(\n",
        "    name=\"documents_collection\",\n",
        "    embedding_function=sentence_transformer_ef\n",
        ")\n",
        "\n",
        "# Process and add documents from a folder\n",
        "folder_path = \"/content/Untitled Folder\"\n",
        "process_and_add_documents(collection, folder_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wN-Fl-dO6P6H",
        "outputId": "68c11ff6-c176-4837-bc7b-35bd1b71dc92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing company_rules_and_regulations.docx...\n",
            "Added 13 chunks to collection\n",
            "Processing company_info.docx...\n",
            "Added 18 chunks to collection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def semantic_search(collection, query: str, n_results: int = 2):\n",
        "    \"\"\"Perform semantic search on the collection\"\"\"\n",
        "    results = collection.query(\n",
        "        query_texts=[query],\n",
        "        n_results=n_results\n",
        "    )\n",
        "    return results\n",
        "\n",
        "def get_context_with_sources(results):\n",
        "    \"\"\"Extract context and source information from search results\"\"\"\n",
        "    # Combine document chunks into a single context\n",
        "    context = \"\\n\\n\".join(results['documents'][0])\n",
        "\n",
        "    # Format sources with metadata\n",
        "    sources = [\n",
        "        f\"{meta['source']} (chunk {meta['chunk']})\"\n",
        "        for meta in results['metadatas'][0]\n",
        "    ]\n",
        "\n",
        "    return context, sources\n"
      ],
      "metadata": {
        "id": "tzHM1Byz6-Wi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_search_results(results):\n",
        "    \"\"\"Print formatted search results\"\"\"\n",
        "    print(\"\\nSearch Results:\\n\" + \"-\" * 50)\n",
        "\n",
        "    for i in range(len(results['documents'][0])):\n",
        "        doc = results['documents'][0][i]\n",
        "        meta = results['metadatas'][0][i]\n",
        "        distance = results['distances'][0][i]\n",
        "\n",
        "        print(f\"\\nResult {i + 1}\")\n",
        "        print(f\"Source: {meta['source']}, Chunk {meta['chunk']}\")\n",
        "        print(f\"Distance: {distance}\")\n",
        "        print(f\"Content: {doc}\\n\")\n"
      ],
      "metadata": {
        "id": "bksspioE7OP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Set your API key\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"api-key\"\n",
        "\n",
        "from openai import OpenAI\n",
        "# Initialize OpenAI client\n",
        "client = OpenAI()\n",
        "\n"
      ],
      "metadata": {
        "id": "g2es0QSN7gKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_prompt(context: str, conversation_history: str, query: str):\n",
        "    \"\"\"Generate a prompt combining context, history, and query\"\"\"\n",
        "    prompt = f\"\"\"Based on the following context and conversation history,\n",
        "    please provide a relevant and contextual response. If the answer cannot\n",
        "    be derived from the context, only use the conversation history or say\n",
        "    \"I cannot answer this based on the provided information.\"\n",
        "\n",
        "    Context from documents:\n",
        "    {context}\n",
        "\n",
        "    Previous conversation:\n",
        "    {conversation_history}\n",
        "\n",
        "    Human: {query}\n",
        "\n",
        "    Assistant:\"\"\"\n",
        "\n",
        "    return prompt\n",
        "\n",
        "# Updated generate response function with conversation history also passed for Chatbot Memory\n",
        "def generate_response(query: str, context: str, conversation_history: str = \"\"):\n",
        "    \"\"\"Generate a response using OpenAI with conversation history\"\"\"\n",
        "    prompt = get_prompt(context, conversation_history, query)\n",
        "    # print(prompt)\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0,\n",
        "        max_tokens=500\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "P9j5Myz_8v8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rag_query(collection, query: str, n_chunks: int = 2):\n",
        "    \"\"\"Perform RAG query: retrieve relevant chunks and generate answer\"\"\"\n",
        "    # Get relevant chunks\n",
        "    results = semantic_search(collection, query, n_chunks)\n",
        "    context, sources = get_context_with_sources(results)\n",
        "\n",
        "    # Generate response\n",
        "    response = generate_response(query, context)\n",
        "\n",
        "    return response, sources\n"
      ],
      "metadata": {
        "id": "6fc9mOLv9J2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Give me summary about NovaCore Solutions?\"\n",
        "response, sources = rag_query(collection, query)\n",
        "\n",
        "# Print results\n",
        "print(\"\\nQuery:\", query)\n",
        "print(\"\\nAnswer:\", response)\n",
        "print(\"\\nSources used:\")\n",
        "for source in sources:\n",
        "    print(f\"- {source}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1yMIeAg9PfC",
        "outputId": "97cd3740-0b01-4245-d1cb-b152662a6fdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Query: Give me summary about NovaCore Solutions?\n",
            "\n",
            "Answer: NovaCore Solutions is an innovative, technology-driven organization that focuses on delivering next-generation digital solutions to businesses worldwide. The company has a diverse team of engineers, designers, analysts, and consultants who bring deep industry knowledge and technical expertise. NovaCore is committed to sustainability and social responsibility, and its collaborative culture encourages creativity, accountability, and continuous learning. Founded with the vision of transforming enterprises through intelligent technology, NovaCore blends creativity, engineering excellence, and data-driven strategies to help organizations achieve sustainable growth.\n",
            "\n",
            "Sources used:\n",
            "- company_info.docx (chunk 4)\n",
            "- company_info.docx (chunk 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\n",
        "from datetime import datetime\n",
        "import json\n"
      ],
      "metadata": {
        "id": "2syfK5Ry_6gs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In-memory conversation store\n",
        "conversations = {}\n",
        "\n",
        "def create_session():\n",
        "    \"\"\"Create a new conversation session\"\"\"\n",
        "    session_id = str(uuid.uuid4())\n",
        "    conversations[session_id] = []\n",
        "    return session_id\n",
        "\n",
        "def add_message(session_id: str, role: str, content: str):\n",
        "    \"\"\"Add a message to the conversation history\"\"\"\n",
        "    if session_id not in conversations:\n",
        "        conversations[session_id] = []\n",
        "\n",
        "    conversations[session_id].append({\n",
        "        \"role\": role,\n",
        "        \"content\": content,\n",
        "        \"timestamp\": datetime.now().isoformat()\n",
        "    })\n"
      ],
      "metadata": {
        "id": "wGp1lPuL_9Wg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_conversation_history(session_id: str, max_messages: int = None):\n",
        "    \"\"\"Get conversation history for a session\"\"\"\n",
        "    if session_id not in conversations:\n",
        "        return []\n",
        "\n",
        "    history = conversations[session_id]\n",
        "    if max_messages:\n",
        "        history = history[-max_messages:]\n",
        "\n",
        "    return history\n",
        "\n",
        "def format_history_for_prompt(session_id: str, max_messages: int = 5):\n",
        "    \"\"\"Format conversation history for inclusion in prompts\"\"\"\n",
        "    history = get_conversation_history(session_id, max_messages)\n",
        "    formatted_history = \"\"\n",
        "\n",
        "    for msg in history:\n",
        "        role = \"Human\" if msg[\"role\"] == \"user\" else \"Assistant\"\n",
        "        formatted_history += f\"{role}: {msg['content']}\\n\\n\"\n",
        "\n",
        "    return formatted_history.strip()\n"
      ],
      "metadata": {
        "id": "J--DK3HVAKO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def contextualize_query(query: str, conversation_history: str, client: OpenAI):\n",
        "    \"\"\"Convert follow-up questions into standalone queries\"\"\"\n",
        "    contextualize_prompt = \"\"\"Given a chat history and the latest user question\n",
        "    which might reference context in the chat history, formulate a standalone\n",
        "    question which can be understood without the chat history. Do NOT answer\n",
        "    the question, just reformulate it if needed and otherwise return it as is.\"\"\"\n",
        "\n",
        "    try:\n",
        "        completion = client.chat.completions.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": contextualize_prompt},\n",
        "                {\"role\": \"user\", \"content\": f\"Chat history:\\n{conversation_history}\\n\\nQuestion:\\n{query}\"}\n",
        "            ]\n",
        "        )\n",
        "        return completion.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        print(f\"Error contextualizing query: {str(e)}\")\n",
        "        return query  # Fallback to original query\n"
      ],
      "metadata": {
        "id": "cez4jxrgBngD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conversational_rag_query(\n",
        "    collection,\n",
        "    query: str,\n",
        "    session_id: str,\n",
        "    n_chunks: int = 3\n",
        "):\n",
        "    \"\"\"Perform RAG query with conversation history\"\"\"\n",
        "    # Get conversation history\n",
        "    conversation_history = format_history_for_prompt(session_id)\n",
        "\n",
        "    # Handle follo up questions\n",
        "    query = contextualize_query(query, conversation_history, client)\n",
        "    print(\"Contextualized Query:\", query)\n",
        "\n",
        "    # Get relevant chunks\n",
        "    context, sources = get_context_with_sources(\n",
        "        semantic_search(collection, query, n_chunks)\n",
        "    )\n",
        "    #print(\"Context:\", context)\n",
        "    #print(\"Sources:\", sources)\n",
        "\n",
        "\n",
        "    response = generate_response(query, context, conversation_history)\n",
        "\n",
        "    # Add to conversation history\n",
        "    add_message(session_id, \"user\", query)\n",
        "    add_message(session_id, \"assistant\", response)\n",
        "\n",
        "    return response, sources\n"
      ],
      "metadata": {
        "id": "uL-TzT4zDHJt"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ðŸ¤– Chatbot started. Type 'exit' to quit.\\n\")\n",
        "\n",
        "session_id = create_session()\n",
        "\n",
        "while True:\n",
        "    query = input(\"You: \")\n",
        "\n",
        "    if query.lower() in [\"exit\", \"quit\"]:\n",
        "        print(\"ðŸ‘‹ Ending session...\")\n",
        "        conversations.pop(session_id, None)\n",
        "        break\n",
        "\n",
        "    response, sources = conversational_rag_query(\n",
        "        collection,\n",
        "        query,\n",
        "        session_id\n",
        "    )\n",
        "\n",
        "    print(\"\\nBot:\", response)\n",
        "    print(\"-\" * 50)"
      ],
      "metadata": {
        "id": "gwdNPqhwDgR7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "295a9c7f-d21e-427c-8ac0-bb80496b0123"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ¤– Chatbot started. Type 'exit' to quit.\n",
            "\n",
            "You: Brief me about Novacore solutions pvt ltd in less than 50 words\n",
            "Contextualized Query: What can you tell me about Novacore Solutions Pvt Ltd in a concise summary of less than 50 words?\n",
            "\n",
            "Bot: NovaCore Solutions Pvt. Ltd. is a technology-driven organization delivering innovative digital solutions globally, aiming for sustainable growth through creativity, engineering, and data strategies. They focus on empowering businesses in their digital transformation with a diverse, collaborative team committed to sustainability and social responsibility.\n",
            "--------------------------------------------------\n",
            "You: Tell me about the workplace behaviour of the company\n",
            "Contextualized Query: What can you tell me about the workplace behavior at Novacore Solutions Pvt. Ltd.?\n",
            "\n",
            "Bot: NovaCore Solutions Pvt. Ltd. promotes a safe, inclusive, and respectful work environment. Harassment, discrimination, or any form of inappropriate behavior is not tolerated, ensuring all employees maintain the highest standards of professional behavior.\n",
            "--------------------------------------------------\n",
            "You: Give me any 3 rules of the company\n",
            "Contextualized Query: What are three rules of conduct at NovaCore Solutions Pvt. Ltd.?\n",
            "\n",
            "Bot: 1. All employees are expected to maintain the highest standards of professional behavior, demonstrating integrity, honesty, and respect toward colleagues, clients, and partners at all times.\n",
            "2. Employees must comply with local, national, and international laws relevant to their job roles.\n",
            "3. Violation of company rules may result in warnings, suspension, or termination depending on the severity of the offense.\n",
            "--------------------------------------------------\n",
            "You: Can you give me the headcount of Flipkart?\n",
            "Contextualized Query: What is the employee headcount at Flipkart?\n",
            "\n",
            "Bot: I cannot answer this based on the provided information.\n",
            "--------------------------------------------------\n",
            "You: exit\n",
            "ðŸ‘‹ Ending session...\n"
          ]
        }
      ]
    }
  ]
}